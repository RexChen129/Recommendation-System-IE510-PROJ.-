{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Artifical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data2():\n",
    "    r=5\n",
    "    n=1000\n",
    "    dataset=torch.zeros(n,n)\n",
    "    #np.random.seed(0)\n",
    "    score=torch.tensor(np.random.randint(1, 6, 10000))\n",
    "    score_2norm=[]\n",
    "    for i in score:\n",
    "        dataset[np.random.randint(0,n)][np.random.randint(0,n)]=i\n",
    "        score_2norm.append(pow(i,2))\n",
    "    #torch.manual_seed(2020)\n",
    "    user2=torch.rand(n,r)\n",
    "    #torch.manual_seed(2020)\n",
    "    item2=torch.rand(n,r)\n",
    "    return dataset,user2,item2,sum(score_2norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect and deal with Netflix Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Netflix():\n",
    "    from collections import defaultdict\n",
    "    f = open(\"combined_data_1.txt\",\"r\")\n",
    "    lines = f.readlines()\n",
    "    lines=lines[:100000]\n",
    "    movie=[]\n",
    "    user=defaultdict(list)\n",
    "    for line in lines:\n",
    "        item = line.split(',')\n",
    "        i=0\n",
    "        if len(item)==1:\n",
    "            item=item[0].split(\":\")\n",
    "            movie.append(int(item[0]))\n",
    "            movie_name=item[0]\n",
    "            continue\n",
    "        user[int(item[0])].append(int(item[1]))\n",
    "        user[int(item[0])].append(movie_name)\n",
    "    user_index=list(enumerate(user))\n",
    "    location_list=[]\n",
    "    score_list=[]\n",
    "    for i in range(len(user)):\n",
    "        for j in range(len(user[user_index[i][1]])):\n",
    "            if j%2==0:\n",
    "                score_list.append(user[user_index[i][1]][j])\n",
    "            else:\n",
    "                location_list.append([i,int(user[user_index[i][1]][j])])\n",
    "    M=len(user)\n",
    "    N=max(movie)+1\n",
    "    print(M,\"users\")\n",
    "    print(N,\"movies\")\n",
    "    print(len(score_list),\"scores\")\n",
    "    r=3\n",
    "    dataset = torch.zeros(M, N)\n",
    "    score_2norm=[]\n",
    "    for i in range(len(score_list)):\n",
    "        dataset[location_list[i][0]][location_list[i][1]]=score_list[i]\n",
    "        score_2norm.append(pow(score_list[i],2))\n",
    "    user2=torch.rand(M,r)\n",
    "    item2=torch.rand(N,r)\n",
    "    return dataset,user2,item2,location_list,sum(score_2norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for Artifical data to search the valid location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_location(data_tmp):\n",
    "    location_list_tmp=[]\n",
    "    m, n = list(data_tmp.size())\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            if data_tmp[i][j]!=0:\n",
    "                location_list_tmp.append([i,j])\n",
    "    return location_list_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CGD algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CGD(users_tmp,items_tmp,I,loc_list,sum_s,alpha=0.01):\n",
    "    start = time.process_time()\n",
    "    loss_list = []\n",
    "    RSME=[]\n",
    "    users=deepcopy(users_tmp)\n",
    "    items=deepcopy(items_tmp)\n",
    "    loc_list_tmp=deepcopy(loc_list)\n",
    "    for iter in range(iteration_time):\n",
    "        loss=0\n",
    "        for loc in loc_list_tmp:\n",
    "            e=I[loc[0]][loc[1]]-torch.matmul(users[loc[0]],items[loc[1]])\n",
    "            users[loc[0]]=users[loc[0]]+alpha*2*items[loc[1]]*e\n",
    "            items[loc[1]]=items[loc[1]]+alpha*2*users[loc[0]]*e\n",
    "        for loc_l in loc_list_tmp:\n",
    "            loss += torch.norm(I[loc_l[0]][loc_l[1]] - torch.matmul(users[loc_l[0]], items[loc_l[1]]), 2)\n",
    "        loss_list.append(loss)\n",
    "        RSME.append(loss/sum_s)\n",
    "    print(RSME[-1],\"CGD Loss\")\n",
    "    end = time.process_time()\n",
    "    print(end-start,\"CGD TIME\")\n",
    "    return(RSME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CGD with Regularization Term algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CGD_bias(users_tmp,items_tmp,I,loc_list,sum_s,alpha=0.01,l=0.01):\n",
    "    start = time.process_time()\n",
    "    loss_list = []\n",
    "    RSME=[]\n",
    "    users=deepcopy(users_tmp)\n",
    "    items=deepcopy(items_tmp)\n",
    "    loc_list_tmp=deepcopy(loc_list)\n",
    "    for iter in range(iteration_time):\n",
    "        loss=0\n",
    "        for loc in loc_list_tmp:\n",
    "            e=I[loc[0]][loc[1]] - torch.matmul(users[loc[0]], items[loc[1]])\n",
    "            users[loc[0]]=users[loc[0]]+alpha*2*(items[loc[1]]*e-l*users[loc[0]])\n",
    "            items[loc[1]]=items[loc[1]]+alpha*2*(users[loc[0]]*e-l*items[loc[1]])\n",
    "        for loc_l in loc_list_tmp:\n",
    "            loss += torch.norm(I[loc_l[0]][loc_l[1]] - torch.matmul(users[loc_l[0]], items[loc_l[1]]), 2)\n",
    "        loss_list.append(loss)\n",
    "        RSME.append(loss/sum_s)\n",
    "    print(RSME[-1],\"CGD_bias Loss\")\n",
    "    end = time.process_time()\n",
    "    print(end-start,\"CGD_bias TIME\")\n",
    "    return(RSME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CGD with Armijo rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CGD_arm(users_tmp,items_tmp,I,loc_list,sum_s,s=0.03,beta=0.85,sigma = 0.375):\n",
    "    start = time.process_time()\n",
    "    loss_list = []\n",
    "    RSME=[]\n",
    "    users=deepcopy(users_tmp)\n",
    "    items=deepcopy(items_tmp)\n",
    "    loc_list_tmp=deepcopy(loc_list)\n",
    "    for iter in range(iteration_time):\n",
    "        alpha = pow(beta, iter) * s\n",
    "        loss=0\n",
    "        for loc in loc_list_tmp:\n",
    "            e=I[loc[0]][loc[1]]-torch.matmul(users[loc[0]],items[loc[1]])\n",
    "            users[loc[0]]=users[loc[0]]+sigma*alpha*2*items[loc[1]]*e\n",
    "            items[loc[1]]=items[loc[1]]+sigma*alpha*2*users[loc[0]]*e\n",
    "        for loc_l in loc_list_tmp:\n",
    "            loss += torch.norm(I[loc_l[0]][loc_l[1]] - torch.matmul(users[loc_l[0]], items[loc_l[1]]), 2)\n",
    "        loss_list.append(loss)\n",
    "        RSME.append(loss/sum_s)\n",
    "    print(RSME[-1],\"CGD_ARM Loss\")\n",
    "    end = time.process_time()\n",
    "    print(end-start,\"CGD_ARM TIME\")\n",
    "    return(RSME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-batch SGD algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(users_tmp,items_tmp,I,loc_list,sum_s,alpha=0.01):\n",
    "    start=time.process_time()\n",
    "    loss_list = []\n",
    "    RSME=[]\n",
    "    users=deepcopy(users_tmp)\n",
    "    items=deepcopy(items_tmp)\n",
    "    loc_list_tmp=deepcopy(loc_list)\n",
    "    n=len(loc_list)\n",
    "    for iter in range(iteration_time):\n",
    "        np.random.shuffle(loc_list_tmp)\n",
    "        loc_list_tmp2=loc_list_tmp[0:round(0.2*n)]\n",
    "        loss=0\n",
    "        for loc in loc_list_tmp2:\n",
    "            e=I[loc[0]][loc[1]] - torch.matmul(users[loc[0]], items[loc[1]])\n",
    "            users[loc[0]]=users[loc[0]]+alpha*2*(items[loc[1]]*e)\n",
    "            items[loc[1]]=items[loc[1]]+alpha*2*(users[loc[0]]*e)\n",
    "        for loc_l in loc_list:\n",
    "            loss+=torch.norm(I[loc_l[0]][loc_l[1]]-torch.matmul(users[loc_l[0]],items[loc_l[1]]),2)\n",
    "        loss_list.append(loss)\n",
    "        RSME.append(loss/sum_s)\n",
    "    print(RSME[-1],\"SGD RSME\")\n",
    "    end=time.process_time()\n",
    "    print(end-start,\"SGD time\")\n",
    "    return(RSME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CGD with momentum algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HB(users_tmp2,items_tmp2,I,loc_list,sum_s,alpha=0.01,beta=0.0001):\n",
    "    start=time.process_time()\n",
    "    loss_list = []\n",
    "    RSME = []\n",
    "    users=deepcopy(users_tmp2)\n",
    "    items=deepcopy(items_tmp2)\n",
    "    loc_list_tmp=deepcopy(loc_list)\n",
    "    for iter in range(iteration_time):\n",
    "        loss=0\n",
    "        users_old=deepcopy(users)\n",
    "        items_old=deepcopy(items)\n",
    "        for loc in loc_list_tmp:\n",
    "            e=I[loc[0]][loc[1]]-torch.matmul(users[loc[0]],items[loc[1]])\n",
    "            users[loc[0]]=users[loc[0]]+alpha*2*items[loc[1]]*e+beta*(users[loc[0]]-users_old[loc[0]])\n",
    "            items[loc[1]]=items[loc[1]]+alpha*2*users[loc[0]]*e+beta*(items[loc[1]]-items_old[loc[1]])\n",
    "        for loc_l in loc_list:\n",
    "            loss += torch.norm(I[loc_l[0]][loc_l[1]] - torch.matmul(users[loc_l[0]], items[loc_l[1]]), 2)\n",
    "        loss_list.append(loss)\n",
    "        RSME.append(loss / sum_s)\n",
    "    print(RSME[-1], \"HB RSME\")\n",
    "    print(time.process_time()-start,\"HB TIME\")\n",
    "    return(RSME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,USERS,ITEMS,location_list,sum_sc=get_Netflix()\n",
    "#location_list=search_location(data)\n",
    "iteration_time=20\n",
    "Loss_list=CGD(USERS,ITEMS,data,location_list,sum_sc)\n",
    "Loss_list1=SGD(USERS,ITEMS,data,location_list,sum_sc)\n",
    "Loss_list2=HB(USERS,ITEMS,data,location_list,sum_sc)\n",
    "Loss_list3=CGD_bias(USERS,ITEMS,data,location_list,sum_sc)\n",
    "Loss_list4=CGD_arm(USERS,ITEMS,data,location_list,sum_sc)\n",
    "\n",
    "itr_time = range(0, iteration_time)\n",
    "# itr_time2 = range(0, iteration_time)\n",
    "plt.plot(itr_time, Loss_list,label='CGD with alpha=0.01')\n",
    "plt.plot(itr_time, Loss_list1,label='SGD with alpha=0.01')\n",
    "plt.plot(itr_time, Loss_list2,label='CGD_HB with alpha=0.01,beta=0.0001')\n",
    "plt.plot(itr_time, Loss_list3,label='CGD_bias with alpha=0.01,lambda=0.01')\n",
    "plt.plot(itr_time, Loss_list4,label='CGD with Armijo Rules')\n",
    "plt.title('RSME v.s. Iteration for Netflix-1000000')\n",
    "plt.ylabel('RSME')\n",
    "plt.xlabel(\"Iteration time\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
